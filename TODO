### 実行環境

### モデル案
- 代名詞と正解の選択肢の関係がなにかあるのではないだろうか？
    - 少なくとも近い方が正解の選択肢となるようにはなっていなかった
- 女性か男性かわかれば代名詞から正しい選択肢を判定できるのではないか
    - 名前での性別判断は有効だ（ほとんど重複はない）が、選択肢がそもそもどちらも同性であったり、どちらも学習データには含まれない事が多く、問題を特には有効ではなかった
- bag-of-pos の形式で処理することで、0.8くらいのスコアを達成
    - 論文の70%くらいというテストデータ正答率の場合上記スコアは、0.4-0.7くらいだと考えられる。
    - position付きのPOSやn-gramを特徴量にしてみても精度は大差なし
    - 「.」や「,」がPOSとなってしまうものを除去してみたが、特に効果なし
    - XGBoost に変更することで大きめの特徴量を使用してもloglossが低くなった。精度はあまり変わらない
- TF-IDFをベクトル化してか作っても、学習データの精度は向上するがテストデータの精度は下がってしまった
- optuna を使用したハイパーパラメーターチューニングで多少改善する。しかし根本的に材料が足りない場合は、すごく改善するということはない
- ターゲットの性別を表すフラグを説明変数に加えてみるのは、多少の改善は見られるが大きくは変わらない
- インデックスや文字番号をフラグとして追加してもそんなに効果はない
- どれくらい正例と負例とでPOSタグに差があるかをみるだけでは、正例と負例を区別できない
    - ただし、異なっている品詞と位置の関係は見られる。
      負例では、ターゲットに続く単語が固有名詞である事が多い。負例は複数単語化なる人名であることが多い？
- dependency関連の特徴量を増やすことで、ちょっとずつだが精度は改善していく。ログロスは頭打ちになっていく

### 実装
- 4層のDNN+dropout+BNを試す
- Aにマッチするか、Bにマッチするかをここに判別し、最終的にトータルするモデルを実装
- XPOSの結果をbag-of-featureとして使用する
- scoreやどの問題を間違えたかを自動計算するプログラムの実装
- BERTでテキストと対象、名前をそれぞれ区切り文字で区切った上で入力する（BERTは単語単位でないのでEmbeddingの心配はない。）
- Pronounを[target]にAと全く同じ単語を[A]にBと全く同じ単語を[B]に置き換えた文をRNNに入力して、出力で3値分類するモデルを作成
- QAタスクのノウハウを使用して、factoid問題として解く

### 問題になりそうな点
- 学習用データが2000と少なく、タスクに必要な情報をそれからだけでは得られなさそう
    - BERTなどの学習済みの言語モデルを使用する
    - 品詞情報などの単語に依存しない要素で学習するようにする
    - 選択肢と代名詞が含まれる文のみを学習や推定に利用する
- 名前の部分が語彙から確実にモデルことが考えられる
    - 同じ名称を使用している語を共通の記号に置き換える
    - 上記に加え同じ人物を指すと思われる単語を識別し同様に記号に置き換える
